Retrieval-Augmented Generation (RAG) API
This project demonstrates the implementation of a Retrieval-Augmented Generation (RAG) pipeline using FastAPI to expose a high-performance REST endpoint. The solution orchestrates data retrieval, indexing, and LLM communication via LangChain. It uses sentence-transformers for document embedding, Chroma as the vector store, and integrates Groq for rapid response generation. This showcases proficiency in building modern, scalable Generative AI applications, effective management of secrets, and deployment-ready architecture (designed for future Docker containerization and Postgres integration).